{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bank Term Deposit Acceptance forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obiettivo di questo assignment è la valutazione delle competenze tecniche del candidato e la sua modalità di approccio ad un problema di Data Science. Nello specifico è richiesto di sviluppare un modello predittivo in grado di indicare se un cliente intercettato da una campagna di marketing da parte di una banca decide di sottoscrivere o meno un deposito bancario a termine (bank term deposit).\n",
    "\n",
    "#### Dataset: ####\n",
    "\n",
    "All'interno della cartella **data**  viene fornito il file **bank-dataset.csv** che contiene le campagne marketing telefoniche effettuate da una banca per proporre l'acquisto del prodotto bancario.\n",
    "I dettagli del dataset sono forniti all'interno del file: **bank-names.txt**.\n",
    "La variabile target che indica se il cliente accetta o meno la sottoscrizione del deposito bancario è contenuta nel medesimo file con field name \"y\".\n",
    "\n",
    "#### Assignement: ####\n",
    "\n",
    "Richiesta di questo assignment è la costruzione di un modello predittivo con performance soddisfacenti per il candidato dando evidenza di tutti gli step tipici che dovrebbero essere affrontati in un progetto di Data Science: dalla pulizia e preparazione del dato fino al testing delle performance del modello costruito.\n",
    "\n",
    "Il notebook svolto dovrà essere opportunamente commentato e dovrà essere consegnato tramite condivisione di un repository github personale accessibile che ne permetta la riproduzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9affd11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, RocCurveDisplay, SCORERS\n",
    "#from focal_loss import BinaryFocalLoss\n",
    "from typing import Tuple, Union\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "from ray import tune\n",
    "from xgboost_ray import RayDMatrix, RayParams, train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620a5f41",
   "metadata": {},
   "source": [
    "## Data Loader\n",
    "The data are loaded and parsed from the .csv file and store into a tf.data object\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a58d9627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(data_path:str='data/bank-dataset.csv', features_path:str='data/features.yaml', raw:bool=False, debug:bool=False) -> Tuple[pd.DataFrame, np.array, dict]:\n",
    "    \"\"\"\n",
    "    Load the data.csv as pandas DataFrame and clean the dataset\n",
    "\n",
    "    Args:\n",
    "        data_path (str, optional): relative path to data.csv. Defaults to 'data/bank-dataset.csv'.\n",
    "        features_path (str, optional): relative path to feature specs. Defaults to 'data/features.yaml'.\n",
    "        raw (bool, optional): skip the cleaning phase. Defaults to False.bit_length.\n",
    "        debug (bool, optional): informative print. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: loaded and cleaned dataset\n",
    "        dict: loaded features specs\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(data_path)\n",
    "    features = yaml.load(open(features_path, 'r'), Loader=yaml.SafeLoader)\n",
    "    if raw: df, features\n",
    "    n_samples = df.shape[0]\n",
    "    n_pos = df.y.value_counts()['yes']\n",
    "\n",
    "    # handle the empty cells\n",
    "    df.loc[df.contact.isnull(), 'contact'] = 'unknown'\n",
    "    df.loc[df.poutcome.isnull(), 'poutcome'] = 'unknown'\n",
    "    df.loc[df.duration.isnull(), 'duration'] = -1.0\n",
    "    df = df.dropna(axis=0, how='any')\n",
    "\n",
    "    for feat, specs in features.items():\n",
    "        \n",
    "        # remove samples with outliers numerical values\n",
    "        if specs['type'] == 'numerical':\n",
    "            if 'max' in specs and specs['max'] is not None:\n",
    "                max_val = specs['max']\n",
    "                if max_val < 1: max_val = df[feat].quantile(max_val)\n",
    "                df = df.drop(df[df[feat] > max_val].index)\n",
    "        \n",
    "        # set string value to lowercase\n",
    "        elif specs['type'] in ['ordinal', 'categorical']:\n",
    "            df[feat] = df[feat].map(lambda x: x.lower())\n",
    "    \n",
    "    # reformat marital status\n",
    "    df.loc[df.marital == 'divrcd', 'marital'] = 'divorced'\n",
    "    df.loc[df.marital == 's', 'marital'] = 'single'\n",
    "    df.loc[df.marital == 'singl', 'marital'] = 'single'\n",
    "    \n",
    "    # make the output binary\n",
    "    #df.y = np.where(df.y=='yes', 1, 0)\n",
    "    \n",
    "    if debug: \n",
    "        print(f\"Dropped {n_samples-df.shape[0]} ({100*(n_samples-df.shape[0])/n_samples:.1f}%) samples\")\n",
    "        print(f\"Dropped {n_pos-df.y.value_counts()['yes']} ({100*(n_pos-df.y.value_counts()['yes'])/n_pos:.1f}%) positive samples\")\n",
    "    return df, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6c752bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def midsampling(df:pd.DataFrame, debug:bool=False) -> pd.DataFrame:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataset loaded as pandas Dataframe. \n",
    "        debug (bool, optional): informative print. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: resampled DataFrame.\n",
    "    \"\"\"\n",
    "    info = \"\"\n",
    "    # split the data into different classes\n",
    "    df0 = df[df.y==0]\n",
    "    df1 = df[df.y==1]\n",
    "    info += f\"Unbalance ds (no:{df0.shape[0]}, yes:{df1.shape[0]}) → \"\n",
    "    # resample each class\n",
    "    df0 = resample(df0, n_samples=df.shape[0]//2)\n",
    "    df1 = resample(df1, n_samples=df.shape[0]//2)\n",
    "    info += f\"Resampled ds (no:{df0.shape[0]}, yes:{df1.shape[0]})\"\n",
    "    # merge the resampled classes\n",
    "    df = pd.concat([df0, df1])\n",
    "    if debug: print(info)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31559cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_dataset(df:pd.DataFrame, test_size:Union[int, float]=.2, as_numpy:bool=False, debug:bool=False):\n",
    "    \"\"\"\n",
    "    Take the leaded data and split into two independent sets.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataset loaded as pandas Dataframe. \n",
    "        test_size (int|float, optional): \n",
    "            If <1 portion of dataset to use as test, \n",
    "            otherwise the number of samples. Defaults to 0.2.\n",
    "        as_numpy (bool, optional): return arrays instead of dataset\n",
    "        debug (bool, optional): informative print. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        list(tf.data.Dataset): train and test dataset\n",
    "        list(np.array): train/test features/labels arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(df.drop(columns='y'), df.y, test_size=test_size, stratify=df.y, random_state=RND_SEED)\n",
    "    if debug: print(f\"Train samples: {x_train.shape[0]}, Test samples: {x_test.shape[0]}\")\n",
    "    \n",
    "    # make feature dataframe a dict\n",
    "    x_train = {name:np.array(values) for name, values in x_train.items()}\n",
    "    x_test = {name:np.array(values) for name, values in x_test.items()}\n",
    "    # make label datafram a binary array\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    if as_numpy:\n",
    "        return x_train, x_test, y_train, y_test\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "    \n",
    "    return train_ds, test_ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f153b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Export pandas report to study the data distribution\n",
    "df_feature, df_label, features = load_df()\n",
    "df_profile = df.profile_report(minimal=True)\n",
    "df_profile.to_file(output_file='data/report_refactor.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24076ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, features = load_df(raw=False)\n",
    "df.loc[df.y=='no', 'y'] = 0\n",
    "df.loc[df.y=='yes', 'y'] = 1\n",
    "\n",
    "fig, axarr = plt.subplots(2, 2, figsize=(20, 12))\n",
    "sns.histplot(x=df['age'], hue=df['y'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axarr[0][0])\n",
    "sns.histplot(x=df['job'], hue=df['y'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axarr[0][1])\n",
    "sns.histplot(x=df['marital'], hue=df['y'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axarr[1][0])\n",
    "sns.histplot(x=df['education'], hue=df['y'], multiple=\"dodge\", stat='density', shrink=0.8, common_norm=False, ax=axarr[1][1])\n",
    "\n",
    "#sns.countplot(x='age', hue='y',data=df, ax=axarr[0][0])\n",
    "#sns.countplot(x='job', hue='y',data=df, ax=axarr[0][1])\n",
    "#sns.countplot(x='marital', hue='y',data=df, ax=axarr[1][0])\n",
    "#sns.countplot(x='education', hue='y',data=df, ax=axarr[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ba4832",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, features = load_df(raw=False)\n",
    "df.loc[df.y=='no', 'y'] = 0\n",
    "df.loc[df.y=='yes', 'y'] = 1\n",
    "'''for feat, info in features.items():\n",
    "    if info['type'] != 'numerical' and feat != 'y':\n",
    "        df = df.drop(columns=feat)'''\n",
    "\n",
    "fig, axarr = plt.subplots(2, 2, figsize=(20, 12))\n",
    "sns.boxplot(y='age', x='marital', hue='y',data=df, ax=axarr[0][0])\n",
    "sns.violinplot(data=df, x=\"marital\", y=\"age\", hue=\"y\",\n",
    "               split=True, inner=\"quart\", linewidth=1, ax=axarr[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8bdea",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The model is composed by 2 main parts:\n",
    "\n",
    "#### **Preprocessing model**\n",
    "\n",
    "Take as input a dictionary with the raw data (string and integer values) and return a float tensor that fit the predictive model.\n",
    "       \n",
    "The features are processed as followed:\n",
    "- **Numerifcal** features are normalized between (0, 1)\n",
    "- **Ordinal Categorical** features are mapped as incremental integer\n",
    "- **Categorical** features are One-Hot encoded\n",
    " \n",
    "#### **Predictive model**\n",
    "\n",
    "Take as input the encoded tensor and return the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a51c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_spec(df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create a dict with the shape and type of each feature, \n",
    "    required by the tf.Model initialization\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataset loaded aspandas DataFrame\n",
    "\n",
    "    Returns:\n",
    "        dict: dict with shape and type for each feature\n",
    "    \"\"\"\n",
    "\n",
    "    inputs = {}\n",
    "    _df = df.drop(columns='y') if 'y' in df.columns else df\n",
    "    for name, column in _df.items():\n",
    "        dtype = column.dtype\n",
    "        if dtype == object:\n",
    "            dtype = tf.string\n",
    "        else:\n",
    "            dtype = tf.float32\n",
    "        inputs[name] = tf.keras.Input(shape=(1,), name=name, dtype=dtype)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75ce5033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, features):\n",
    "    for name, value in features.items():\n",
    "        # map each class to an incremental integer\n",
    "        if features[name]['type'] == 'ordinal':\n",
    "            df[name] = df[name].map({feat: i for i, feat in enumerate(features[name]['classes'])})\n",
    "        # one hot encode the categorical features\n",
    "        elif features[name]['type'] == 'categorical':\n",
    "            df = df.assign(**pd.get_dummies(df[name], prefix=name))\n",
    "            df = df.drop(columns=name)\n",
    "        # normalize the numerical data\n",
    "        elif features[name]['type'] == 'numerical':\n",
    "            continue\n",
    "            if 'max' in features[name] and features[name]['max'] is not None:\n",
    "                max_value = features[name]['max']\n",
    "                if max_value < 1: max_value = df[name].quantile(max_value)\n",
    "                df[name] = df[name] / max_value\n",
    "        else:\n",
    "            raise Exception(\"Unknown data type\", features[name]['type'])\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de6951cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessing_model(df:pd.DataFrame, features:dict, inputs:dict) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Initialize the preprocessing model, which take the raw features as input\n",
    "    and return a float tensor that fit the predictive model\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataset as padas DataFrame\n",
    "        features (dict): features specification\n",
    "        inputs (dict): input specs for the tf.Model\n",
    "\n",
    "    Raises:\n",
    "        Exception: unknown feature type\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: model for the input preprocessing\n",
    "    \"\"\"\n",
    "    \n",
    "    preprocessed_inputs = []\n",
    "    for name, value in inputs.items():\n",
    "        # map each class to an incremental integer\n",
    "        if features[name]['type'] == 'ordinal':\n",
    "            layer = tf.keras.layers.StringLookup(vocabulary=features[name]['classes'])\n",
    "            prep_val = layer(value)\n",
    "        # one hot encode the categorical features\n",
    "        elif features[name]['type'] == 'categorical':\n",
    "            layer = tf.keras.layers.StringLookup(vocabulary=features[name]['classes'], output_mode='one_hot')\n",
    "            prep_val = layer(value)\n",
    "        # normalize the numerical data\n",
    "        elif features[name]['type'] == 'numerical':\n",
    "            if 'max' in features[name]:\n",
    "                max_value = features[name]['max']\n",
    "                if max_value < 1: max_value = df[name].quantile(max_value)\n",
    "                prep_val = value / max_value\n",
    "            else:\n",
    "                prep_val = value\n",
    "        else:\n",
    "            raise Exception(\"Unknown data type\", features[name]['type'])\n",
    "        \n",
    "        prep_val = tf.cast(prep_val, tf.float32)\n",
    "        preprocessed_inputs.append(prep_val)\n",
    "    \n",
    "    preprocessing_outputs = tf.keras.layers.Concatenate()(preprocessed_inputs)\n",
    "    preprocessing_model = tf.keras.Model(inputs, preprocessing_outputs, name=\"preprocessing_model\")\n",
    "\n",
    "    return preprocessing_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3536056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(df:pd.DataFrame, features:dict, hidden_units:list, act_function:str) -> tf.keras.Model:\n",
    "    \"\"\"\n",
    "    Initialize the neural network\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataset as padas DataFrame\n",
    "        features (dict): features specification\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: predictive model\n",
    "    \"\"\"\n",
    "    inputs = get_input_spec(df)\n",
    "    preprocessing_model = get_preprocessing_model(df, features, inputs)\n",
    "\n",
    "    layers = []\n",
    "    for units in hidden_units:\n",
    "        layers.append(tf.keras.layers.Dense(units, activation=act_function))\n",
    "    layers.append(tf.keras.layers.Dense(1))\n",
    "    predictive_model = tf.keras.Sequential(layers, name=\"predictive_model\")\n",
    "\n",
    "    output = preprocessing_model(inputs)\n",
    "    output = predictive_model(output)\n",
    "\n",
    "    model = tf.keras.Model(inputs, output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7c6f3d",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ce8ae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_proba, savefig=None):\n",
    "    plt.figure()\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "    roc_display.figure_.set_size_inches(5,5)\n",
    "    plt.plot([0, 1], [0, 1], '--k')\n",
    "    if savefig: plt.savefig(savefig)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_heatmap(y_true, y_pred, savefig=None):\n",
    "    plt.figure()\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    hm = sns.heatmap(conf_matrix, annot=True, fmt=\".2f\", cmap=sns.cm.rocket_r)\n",
    "    hm.set(xlabel='Prediction', ylabel='Ground truth')\n",
    "    hm.set(xticklabels=features['y']['classes'], yticklabels=features['y']['classes'])\n",
    "    if savefig: plt.savefig(savefig)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f370d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "### SINGLE RUN! ###\n",
    "from pathlib import Path\n",
    "\n",
    "def run(config):\n",
    "\n",
    "    df, features = load_df('/home/stefano/Projects/Fastweb/data/bank-dataset.csv', '/home/stefano/Projects/Fastweb/data/features.yaml', debug=False)\n",
    "    df = preprocess_data(df, features)\n",
    "    train_df, test_df = train_test_split(df, test_size=.2, stratify=df.y)\n",
    "    train_df = midsampling(train_df, debug=False)\n",
    "\n",
    "    model = XGBClassifier(use_label_encoder=False, \n",
    "                          eval_metric='auc',\n",
    "                          max_depth=int(config['max_depth']), \n",
    "                          n_estimators=int(config['n_estimators']),\n",
    "                          eta=config['eta'], \n",
    "                          subsample=config['subsample'], \n",
    "                          colsample_bytree=config['colsample_bytree'],\n",
    "                          min_child_weight=config['min_child_weight']\n",
    "                          )\n",
    "    model.fit(train_df.drop(columns='y'), train_df.y)\n",
    "\n",
    "    y_proba = model.predict(test_df.drop(columns='y'), output_margin=True)\n",
    "    y_pred = model.predict(test_df.drop(columns='y'))\n",
    "    \n",
    "    AUC = roc_auc_score(test_df.y, y_proba)\n",
    "    scores = classification_report(test_df.y, y_pred, digits=3, target_names=features['y']['classes'], output_dict=True)\n",
    "\n",
    "    in_ray = True\n",
    "    if in_ray:\n",
    "        return {\"loss\":-AUC, \"status\": STATUS_OK}\n",
    "        tune.session.report({\"AUC\": AUC, \"done\": True})\n",
    "    else:\n",
    "        print(classification_report(test_df.y, y_pred, digits=3, target_names=features['y']['classes']))\n",
    "        print(f\"AUC {AUC:3f}\")\n",
    "        plot_roc_curve(test_df.y, y_proba)\n",
    "        plot_heatmap(test_df.y, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "8defcddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 193 (0.4%) samples\n",
      "Dropped 48 (1.5%) positive samples\n",
      "Unbalance ds (no:31824, yes:2499) → Resampled ds (no:17161, yes:17161)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.98282719, 0.9848218 , 1.1980083 , 0.83306694, 0.91609955,\n",
       "        0.8305285 , 0.8546412 ]),\n",
       " 'score_time': array([0.01203418, 0.01177263, 0.01142621, 0.01291323, 0.01097631,\n",
       "        0.01162887, 0.01220417]),\n",
       " 'test_roc_auc': array([0.99038089, 0.98907244, 0.98875363, 0.98745626, 0.98867077,\n",
       "        0.98910888, 0.99055434]),\n",
       " 'train_roc_auc': array([0.99704012, 0.99707775, 0.99719522, 0.99715926, 0.99692197,\n",
       "        0.99688591, 0.99706897]),\n",
       " 'test_f1': array([0.95535362, 0.95657323, 0.95334124, 0.94968553, 0.95283205,\n",
       "        0.95166994, 0.95853081]),\n",
       " 'train_f1': array([0.97576629, 0.97493593, 0.97417958, 0.97478432, 0.97400347,\n",
       "        0.97259363, 0.97498918])}"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## SCORING CROSS VALIDATION\n",
    "\n",
    "df, features = load_df(debug=True)\n",
    "df = preprocess_data(df, features)\n",
    "train_df, test_df = train_test_split(df, test_size=.2, stratify=df.y)\n",
    "train_df = midsampling(train_df, debug=True)\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='auc', max_depth=23, n_estimators=30,\n",
    "                      eta=0.05, subsample=0.5, colsample_bytree=0.5)\n",
    "\n",
    "scores = cross_validate(model, train_df.drop(columns='y'), train_df.y, scoring=['roc_auc', 'f1'], cv=7, return_train_score=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "57565ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 193 (0.4%) samples\n",
      "Dropped 48 (1.5%) positive samples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxzUlEQVR4nO3deXxc9X3v/9dnzmwajUa7ZO2S9w2bRWAgoWCWBGhSskALhOyEkkJumvxum7S3N2mT2zRN0iRNQ0IIoWlSErJAEhYHSKDsGBvjDePYlm0syZKsfRmNZjnnfH9/jOwIYxthazSS5vN8PAbNWWbm85XMec/5nnO+R4wxKKWUyl2ebBeglFIquzQIlFIqx2kQKKVUjtMgUEqpHKdBoJRSOc6b7QLerLKyMtPY2JjtMpRSalbZtGlTrzGm/FjLZl0QNDY28uKLL2a7DKWUmlVE5MDxlmnXkFJK5TgNAqWUynEaBEopleM0CJRSKsdpECilVI7LWBCIyF0i0i0iLx9nuYjIt0SkRUS2iciZmapFKaXU8WVyj+CHwOUnWH4FsGj8cRPw3QzWopRS6jgydh2BMeYpEWk8wSpXAT8y6XGw14tIkYhUGWM6M1WTUrkglYgTGxokHo3i2DaubePYNo6TwrWd8Xmp9Lzxh2uncBwH17ZxXefIeyUQngwW0efx/fEDjItJpDB2ClwDroNxXXD++JPjDG9vAIPBGHPkp21sbNc+bntc8ZDwBkFe/2YugDGYw29+CgT3uHUf/0UWhvTvxhKLgCcPAI9/DH944NQKOoamvmE+95f/Z8rfN5sXlNUAbROm28fnvS4IROQm0nsN1NfXT0txam5y3SSOExt/jOE4MVw3gZmwFTGuk95gOg6OnTqyIXVtG8dJ/zSui2tcjGswrpt+GJN+rTHguriui5mwjuumNzSu62AmruO6GNtJz3cd3PENctIxPBus4ffFK4h6g0zc2v1xe2WO/DjSBmM4eqspcnhaxv/rAQJAID3HErDGZyHI+DsPBEK4ku44kIkbyfxT/UscVb+alMs8z2fkfbMZBEfnOxznX4Ux5g7gDoDm5mb9l6OOSKVGGBh8gWSii1RqgGRqgFSqn1RqkFRqCNsewXFGcJyx9AbfvP6bp4uQwkcK/5GfyfHnyfHpOHkMUMwApQwTeXObLw/H6IQVbAIk8ZM88tP/mukY+cQlj0rTyXJeQrKw0SxigKXmFVaz+Zj/w54s1/XgOF5SqSCpVIBUKoBj+/Fh4TOv3yz5sIi4wdfMS2dbOrQOFzexRtu1cN2p7f32+i1kwlsK4At68frSM62SIFbET8BfQUXFlUQiK6f08yEzh1KzGQTtQN2E6VqgI0u1qFnCGEMy2UvXoQfo7n6IkZEdGJOasBxiboTf8F4OUkPSBEga//jG3UcKH7Z4SeHF9viwxcLxTP5/AzEuITue7kY4qQYc/kYOlnHxuTY+4+B3HXyuQ4Hr4HNT+E2CoDNA82Ava4ZH8Iy/5o+vBtsYbGNwMbgGbP743B3fP3DhyLR7ePrwPDm8jPRWVSS9WRVB8KQ/T8LAObSyBo8YDB5ksolgBOP4cV1f+qfjPzKNsTC4CB48xsIyASz8xI3gOc4H9LzJX7U/5KNpdRm1S4vf5CuPw0DdspKpea8ZJptBcD9wq4jcA6wBhvT4QG4wxpBKDTA21k480UEi3oFtj5BIdJFI9uA4MVLOGPbh7hs7juvGMSaJGBuR9DfjWCLM9pG3siO1ij5POf3+CMP+MCN5YRyPh5LoIF7HwXIdvI5NwEmR74zhc2zyHCHkCeI3Fj7X4HNcvC74HIPfNfhcg9/hyPOAbShO2BQmbHxi8EoKCxtLXASDR0Aw499P0xszDx4EQcSDYAEejPFgA44RUgi2AdsVkoBtPDgIDoKNkCBAggY24cVjeSnI87GqoZi6ZaWUVIfxVxdk8a+o5pKMBYGI/BS4CCgTkXbg85A+qmKMuR1YB1wJtAAx4MOZqkVNj2RyiNjYPlLJPpLJ3nRXTbKPZKqPeLyXeLwP2x7EcQaBxOteP5byM5byYztejGthHB84fnCKcF3ryGPE5PO47wK2la0iVp7urPalEhQN9VPR3crKoQ6a92zjgpZB8k0x3mAJ5JdiwuV4giWEQuX4LD+jjsvehGE4OYjXv5eQrxPjSeB6HFzLxbHA9Qopy0O/L8LjpeczZJ3cN0LLIwR9HgJei4DXM/6wCPj++NzyCB6BsnCAeQUBKgoCVESClIUD+L16yY/KHJltN69vbm42OvrozNPRcS+79/wTjjP6umW27SeZDGCngiSTeSQSIRLJEMlEiEQif3w6gMdxsRwbr53CayeJBvJpL65iIFTEUF4BA+FC+goijAXTfcVNrbtZunc7ja0tVCR8lAQaKA+cRkmomBJ/4HVdDAnXMObCsOvSJi79lUHmNc+jYUER1UV5FIX8BLyeCQdWlZo7RGSTMab5WMtm3TDUKvtc18W2bRKJBKOjg7S2fYmRkUeJRktpaz1zwgHAIHHHS0xs4uLgGsGfsigc9RJK+ChI+ihO+vEmfcRNgo7SAvZWFdFaWUhrZTHD4fSpeIFEkkg0SmR0hKXdXURGuqnuOsCSkWUsKjiX+ZWX4Zuw8e5zXV5wHDrFMOb34IQsrKIANfWFXPWWBvKL/Jzv0W/YSh2mQaBeo7e3l82bN9Pb20symTzySKVS2LZNKpUilUrhui6h0CBN8zdRUtJBe/syOlreijdahKQ8+GwPflsIO+leb2NSYGwghbgJxI2TJMrzS2vZ01BLR0UtKX8AgPzREeq721i7rZPlXQPMiws+K4zfyifPGybiXUxhsJlQngXAs6Q4ELZYvqKCygVF1NYXsSTfj9/y4PHot3ul3ogGQQ5LJpNEo1Gi0SgHDx5k69atdHV1ARAKhfD5fPh8PsQYrFQSvwwSKmohlN9NflEfwXAM40LrS4107yjAF3vmyOl7h8+psT0W8WCIsfHHaF6YntJ5dJUt41BFDfFgiLLBKM2dcc4ZSnLhANTFQagCqtLnq4+fs24LxH0eYnkWfQVeugr8OKVB6pcWc838Ujz6LV+pk6JBkKM2bNjAunXrXjOvoKCA8847jzPPPJOCcJADrzzG3q2P0Nu5HX84TtGCYXwhh1TMz1hvMYN75zPYVUoyPoLH38OWhc201K3G9oWIB/KJhsLEA8HXfbbHGGptYW0c3rE7wZpOAx4Lb3ke/hVhrIgfT9iPFfbhCfvxhH1YBX48eV7tv1cqAzQIcoAxhsHBQTo7O2lvb+fAgQMcPHgQgKuuuoqCggLy8/OprKzEmAQ71t/Nhq5/J1gcI9AINY3gpvzEB5pwfj+fyLZNlAwMsXHFUnY2LuTV+lpera6lt6iE4uFB5vd0UR6LUjnQRYFrEUjmE3BKqLMtimMu9aMufgMSsPDVhMm/ppHg8lKsPP3nqFQ26P95c5DjOIyOjrJv3z62bNlCV1cX8Xj8yPKioiJWrFjBeeedR21tLbYdo639pzz+2H9yEC+jVj6jhUvpbl3OYGwVo6aEMQliJTuxmw4xsOo8esqq6S8oI2AnaYj2s2a0n+WH+nhXaz4BtwYYH1Mm6MVf4MdT4MeK+LGKAvjn5eOvDeMpCWp3jlIzgAbBHLBp0yZaWloYGhoiGo0yOjqK46QHDgsGg9TX11NVVUVVVRXV1dVEIhEgffbPgw9/AY/zCwJ5Me5Pvpufh25Iv6kFNPzxMyw3RcgpJmL7KEmNsjrZyTXbnmRN1yKMaQLyGfUMEg3HKVxZROT0pXirivD4dEOv1EynQTDLtbW18cADDwBQVlZGaWkp8+fPp7i4mIqKChYtWoTX68V1XTb3bObe1nvp2r0V/8atLFzWQ7h2jNGeANueP5unVr+NiMS5aaSfNYe+z7z4PiKBIGFvEOyziI+tYHSkFo9TNP7pjdgBD/mX1lO8ugIrEsja70EpdfI0CGapWCzG3r17ue+++wgEAtx4442Ul5e/br1kRwe/eeaHPLf5N4R6otSNuFwYcRm6QuiNlHFHz6fZF17MwCVhfLj868jjXPuHr2L7V5Bc/W1SyXkMvdyHG00hfg+bvQ47rBT/6z0r8FeH8Zbk4dGrXpWa1TQIZqGXXnqJBx98ENd1sSyLSy+99HUhYPf10f6pTzO2YQOLgcXA0Fkw8BHDXl8FW0dP5x4+hL/U4eLBDZx/cCN/0ttJ0egldDg/gzELngKkC29FiE2LwnzzQA97+2N88pJFhE+vzEbTlVIZoEEwywwPD/Pggw9SWlrKxRdfzIIFC/D7/UeWG8eh74c/pPc738UZG+W+t3jYunw5Pas+RI8VYIASjHggDHWJQR7a9GEqqpbg1p9PZ9tHSVgWodVl+Bsi9IU8rDs0xP07uti5uYu64hD/+M7lfPD8xuz9ApRSU06DYJbYvn07W7ZsoaOjA9d1+bM/+zPq6upet17Pt/6Dvu99j70Nfr7y3tNJ1b6L1uACChlkcewP+A/M56KF81m49wWWdXRh/N+g4+A83D0pMFD6waVEa8Pct72Tf/7ZThK2S0VBgL99+xI+ftECPY9fqTlIg2AWGBkZ4d5778Xj8dDU1MTixYupra19zTqu6xL93e/pv+en7GywuP3Tf8Fu/5UUmz4udR7mgh0dVO97B4tLiwi29QB1WL4SKKrBHwlgFflxSoLc+PRuntvfjzFQHPLxXx85mzVNpRoASs1hGgSzwNatWwH44Ac/SENDw2uWuakU/T/8Lwbuvhu7q4ueQg/33fAWtvmv5JLoem7Z0UfV0Bp8JgghsOIHCVn/Q0Hgl3hu3QAljQDs743ymV9uY8OrA1x/Tj1vW1HJuU2lBP3WdDdXKTXNNAhmsFgsxsMPP8y2bduoqqp6XVdQsrWVtps/TnLfPjwLF/LD97+FfQXVbKi5gqXJvXzhucUMJ23y/E9TEN6PvzSBr6YKylfCgk9ASSNdQ2N85t5tPLm7F4ArV87jS+85LRvNVUpliQbBDOO6Ll1dXbS1tfHcc88xNDTEypUreec73/maq3DdZJL2W27l1XiSf//6HWwPRRgbv7dEjdvGl1/0MZRMUFd1B+Xv+wJUvX7jnkg53PCDF3i1L8YN59Zzw5oGllZFpq2tSqmZQYNghvnBD35wZBwgr9fLhRdeyNq1a48sT+zdS89//Acj61/gD4UlfPNv/4ldgRCr+/ezYP8zvHXVM9R1NVA9fAvll79K3p/8NwTyX/MZrmv4zhMt/OSFVjqG4vzbNat471mvP/CslMoNGgQziOu6dHd309DQwGWXXca8efPwetN/IuO6DN73Kw58+zZ+tOZC1n3uawzm5RMwhivXr2Mt91O9pgeiRVQfeBcjFfnUX/aBI+8dTzkc6Ivx1O4efrW5nVc6R1hUEebL7zlNQ0CpHKdBMIPs3r2bVCrFGWec8Zqzguzubrq+9C8MPfIIn/rsP7OzvolzwwGW7t1G6OFfYrmjlP1FlET3EpZs/RQeCdB/xTw+/t+baBuIcWg4QV80gTt+V9LyggD/32WLufXihXo2kFJKg2AmiMVibNy4kfXr1xMOh1m5cuWRZYP33UfnP/xfcF1euuKd7Kxv4m+K/Vhf/z84iSQHK5KsvTCOP2+MipaFBC0vL15axyd/sYWQ36KmKI8VVRHqS0M0lOZzel0hZ9QV6aifSqkjNAiyyLZtHn/8cTZt2kQikaCsrIx3v/vdeL1enHic4QcepPtrX8MqKaH669/g4yafsngS3w//jVQiyZNnjnI9FxAquZt5uy6hsPMa4vMjfP6pPZTm+3niby6iIOjLdjOVUjOcBkEWPfbYYzz//PNUV1dz6aWXMn/+/CPLDlz/PhKvvIJVXk7d7d/lB+Ey/rCvkwtfeBg72kbP+SP8XdFixqp/gW+klkjb+xhdGOG6ti6MR7jzQ80aAkqpSdEgyJJnnnmG9evXM3/+fG644YYjXTXGGPp+cBeJV16h8D3vofgf/5HfD4zwlR37WJzaw4dW3YX/nPS9BsbsIfL6mll++t+zZ0UZH/jRJkJ+i3tuPJfF8wqy2Tyl1CyiQZAFr776Ko899hjV1dVcc801r+mv7/32bfTedhuBJUuI/P3fceWzL7CTMCES/Gni17T25TE/ejm1sfmE4ouo+fRb6DOGv/z3pwn5LX558/k0luWf4NOVUuq1NAimmTGG3/72twQCAa677jry8vIAcIZHaP/kJ4k9/zxWeTmNv/g5//uZ37JTGrh2/4+4vPEhvt+dx6cOfIPGlI/OkMXdTQE2/+cG9nRHSdku/3H9GRoCSqk3TYNgmu3Zs4dDhw6xdu1awuEw7tgYPd++jcF77sGNxSj5yEcou/lmvt/Ry0+kgQv6fsc76n7D2FAxX+j6EoUpH+vtFP87Nkxgt4e64hCXr6jkYxcs4LTawmw3Tyk1C2kQTLONGzcSCARYs2YNTjzOgWuvI7FrF3lnnUX5J24l/9xzGU0m+fLu7Syz9nJj8R2M9TSwavtnGUgF2Rq3eWFFPr9/19k0lubj1buDKaVOkQbBNOrs7GTv3r0sX76cYDBI/z0/I7FrF2V//UnKb775yHr//KM7GVtwPn8af5DItk9TN7CSAdfwzHCKsRURvnJTs14IppSaMvp1cpq4rstjjz0GwNvf/nZGn3uO7q98BW9lJWU33ZReaWyIjtuv477KJdSb/VzYUU5N4jT2hbw8N5Ji38I8/uYTZ2sIKKWmlAbBNHAchzvvvJOWlhbOOussZOtW2v7yZqyCAmq/dzsyftbQC//+ab7OOxgMl/Ie+yEi3ZewOZLH9o4xNvtdPvXh07PbEKXUnKRdQ9Ngx44ddHR00NzczJVXXsney6/AKiqi8Rc/x1dRAaN9bLn/O/w+EeHuxcs4293AkhdW8/jBQpIyRKfl8JGPraKuNJTtpiil5qCM7hGIyOUisktEWkTks8dYXigiD4jIVhHZISIfzmQ92RCNRnnooYcoKiriwsWLaf+rW0gdOEDh1VenQ+CJf2XXF8/g7vV7ufOt11DMIDfsqGXx266m5ZwI34iMseS6hZyzsjLbTVFKzVEZ2yMQEQu4DbgMaAc2isj9xphXJqx2C/CKMeadIlIO7BKRu40xyUzVNd0effRREokE1196KR3vuwE3Hqfw6qspv+WvANj75G94qP001l97OZbY3LZjF6Vvey8fv38Hrf0x3rm6ig+e35jdRiil5rRMdg2dA7QYY/YBiMg9wFXAxCAwQIGkj36GgX7AzmBN08q2bbZv387CvBCJv/4UJpGg6d5fEly8GIDUWIwn+oOk3l/AHv9SPjb2exZ1n8fHfvsH+keTfOPPV/PuM2vf4FOUUurUZLJrqAZomzDdPj5vom8Dy4AOYDvwSWOMe/QbichNIvKiiLzY09OTqXqnXGtrK8YY5j3yCJ78fKq/9tUjIeC6Dj/+609Qck4PP/O+n3IT4/3PnsNTTpKdh0Z4/7kNGgJKqWmRyT2CY53jaI6afjuwBbgYWAD8TkSeNsYMv+ZFxtwB3AHQ3Nx89HvMWH3t7QBUnnYaC77x9SNnBwE8+d/riNGKr6qYDqnhb18ZI+oYflfp5TuXnMnlK+dlq2ylVI7JZBC0AxPvgVhL+pv/RB8GvmyMMUCLiOwHlgIbMljXtOnbvBmA6muufk0IvLqni82PPsDKq4b5pvlLLGMY7Yuz7x2N3PWWRr1OQCk1rTLZNbQRWCQiTSLiB64F7j9qnVbgEgARqQSWAPsyWNO0aj94kNDYGMXnn39k3qHuNn76lS+y8LQedpZW8ZLnTAr3jJBaVcbVb23SEFBKTbuMBYExxgZuBR4BdgI/N8bsEJGbReTweApfBM4Xke3AY8BnjDG9mappOm3dupWDwSBVsbEjw0wnEwm+97lbmJewiSyK8X3zvwjZhrG2EW44rzG7BSulclZGLygzxqwD1h017/YJzzuAt2WyhmzYs2cPv/71rykeGWFNLJae+eqz3H/nV8kfcDl7yUVsLvoOvVJCYOcglyyqYFFFOLtFK6Vylg4xMcXa29u57777KAgGueh3v6f49NOhZzex/7ye1tYGigK1ONVb2MdCAIodwz+/a6V2CSmlskaDYAqlUil+8pOfICJcNjiEz3Eouvq9tPz4u9zd/XVMsg3/vHK21u3nv8yNBFMuj3/sLVQV5WW7dKVUDtMgmCK2bfPggw8Si8W4uKkJ7wMPEL74YqyQ8FzLGhyrB0yS8oWlfCvvfdiuxf3nLKYk5M926UqpHKdBMEWeeeYZtm7dysKFCyld91us/Hzmff5zvPr404y45ZiGZ6lfE+W+pijt0sB1AYtVRXpcQCmVfRoEU6StrY2CggKuv/563EOH8M1vwmd6eXnTdhou/n8sPus5ulYX8qB1BXUDI3z5guZsl6yUUoAGwZQZGhqisLAQsW1SbW0EFiyg85l1WGc8ib+ok7Ed7+G7qc/hHTVcJIV6cFgpNWNoEEyBRCLB4OAgpaWlJA8cwKRShFafzrbBLQSL2/nDrgU8EHkvI14PbOnjvauqs12yUkodoUEwBTZs2IBt25x11lnENm8BIFYTwKrfAIPl+PaezRPzAhR3J3j3ogrOXVCW3YKVUmoCDYIpsHnzZsrLy6mvr2f44YexSkpobfkRYjl4Ylfw/UuuxBaDdWiMb/7F6dkuVymlXkOD4BSNjIzQ39/PsmXLSLa1E9++HerKGSrZS6J3AXdap9GV7+Nt23ZwRnFYjw0opWYcDYJTtGfPHgAW1tXR+tGPYlIpOs4twBsaIlHxAXYW1LFyIMlgsIb/d9WKLFerlFKvp0Fwil5++WX8fj+hDRtJtbYSfu+5xBoO0BVdyl8nFjEY8LKku52f3LKW6mK9+bxSaubRIDgFY2Nj7N+/n5UrV5La24IrHp4dbSJQdJDvy0ewxMvdz4/yhT+9RLuElFIzlgbBKejr68MYQ1NTE9H/eYJ4fT2m6hAYocNXx2VdNrtDKYrri7JdqlJKHZcGwSloa0vfkjnc0YHd2YmpKcQfPoRxCxj1+RhNHKTs7UuyXKVSSp2YBsEpeOGFFygpKcH/9DO43gB78q4gPzzA/thqHI/Qag9x8ZKKbJeplFInpEFwkkZGRhgcHGTVsmWMPPQgA0vPZHl4Hr6SfWx3z0WM4S+WX0CeP6P3/lFKqVOmQXCSDh48CEDRvn0MW2X0V1yCu2gdxkryQqKEAoRbLlyY5SqVUuqNaRCcpI6ODgD8uw+w6YxPI+4osdIdPBq9kAOVi3lXdWmWK1RKqcnRIDhJ3d3d5AXz2Nw1H4cklX4/O/OD/Dh8C6UO/MOCqmyXqJRSk6JBcJKGh4exRg2DBfM5y7uZsrJ8nvGuQTA8/pblRHx6bEApNTtoEJyk0f4B7ISf8pHtFOQv5mDTT9jFMhaGfFTm6e0nlVKzhwbBSTDGEB2NgQlzRu2j+IJ5HKzpZL8s5B2VerqoUmp20SA4Cb29vTiWEEh6kaoSPPmD7GYpAJeWRLJcnVJKvTnakX0Str70EgA1sS529V7K7tN6+B63UGw5LC/Iy3J1Sin15ugewUnYt2UXHjvAAms33vww3yi/gAqnhV+d3kDAo79SpdTsolutk9A3Mow3lUdl+SL+p85PCh9nJn/B0ojeglIpNftoELxJ8bY2EpZNJCmY1HnsDY5RxABnVJye7dKUUuqkaBC8SV2PPQECtX445Ld4tmQBS8zLLCk7N9ulKaXUSdEgeJMOHugFoNSTz6NlA7hi0Rh7iNWVp2e3MKWUOkkZDQIRuVxEdolIi4h89jjrXCQiW0Rkh4g8mcl6psLQcBSAfFPBhpo4xaaPisgCKkJ6/YBSanbK2OmjImIBtwGXAe3ARhG53xjzyoR1ioDvAJcbY1pFZEZvTY0xDA4OQ0E+IQnQGXEpc9v44Nn/kO3SlFLqpGVyj+AcoMUYs88YkwTuAa46ap3rgfuMMa0AxpjuDNZzyqKPPc6w5UGM0Df/CQ54Gyn1pKgpqMl2aUopddIyGQQ1QNuE6fbxeRMtBopF5AkR2SQiHzjWG4nITSLyooi82NPTk6FyTyzZ28tjd95JV1UeNUGXXQ1bAHjXwsuyUo9SSk2VTAaBHGOeOWraC5wF/CnwduD/isji173ImDuMMc3GmOby8vKpr3QSnv3Sv7Bl6RL8iVIWLXuCV1gFwNnF2alHKaWmSiaDoB2omzBdC3QcY52HjTGjxphe4ClgdQZrOinxXbt5OZHElwpQOFhBNNLL/fJnFMZbWVGQn+3ylFLqlGQyCDYCi0SkSUT8wLXA/Uet8xvgAhHxikgIWAPszGBNJ2XfF/6JvrISfPF5NM57lae5kGFvPtcX6d6AUmr2y9hZQ8YYW0RuBR4BLOAuY8wOEbl5fPntxpidIvIwsA1wgTuNMS9nqqaT1T80BCIUhkrJ93fwCisJ2738eePZ2S5NKaVOWUZHHzXGrAPWHTXv9qOmvwp8NZN1nApjDL1eHwA19VU43f/DXs6hIr6H6sILs1ydUkqdOr2y+A240SjDBYWI66WkNEhnlYc+Kee0nl4ieTqKt1Jq9tMt2Ruwe3sZCRficQL8bt9/89DqSylyh1g7cgiRY50YpZRSs4vuEbyB6I4dDBZH8NohursO0eqt4v2DjxKsbs52aUopNSU0CN7Aq/f8jJTfQpIhInXp+w0s6OvDs0gvJFNKzQ0aBG+gf3gYgFigjZaFjeSZMQ601lAZCWa5MqWUmhoaBCdgjGHIFwCgtrKV3XkLWB3t4x57JaXhQJarU0qpqfGmg0BELBF5XyaKmWlMLEY0P4y4XnZVl3JIqrji1QAD+CnXIFBKzRHHDQIRiYjI34nIt0XkbZL2CWAf8OfTV2L22ENDDBQX4bHz+F3ZWhYnW1nWY1FVGKQw5Mt2eUopNSVOdProj4EB4HngRuBvAD9wlTFmS+ZLy77OJ55kqDiCF6HbM4/39G9heyqf8xaUZrs0pZSaMicKgvnGmNMAROROoBeoN8aMTEtlM0Dr009DZQVdhTYA9VEfO3G57pz6LFemlFJT50THCFKHnxhjHGB/LoWASaU4ODhAzBfgV6suptJ0clZ3kIaFxTQ3FGe7PKWUmjInCoLVIjIsIiMiMgKsmjA9PF0FZovd28twOExfXgmOx8uN7u2UREu55u2L9IpipdScctyuIWOMNZ2FzDSpzk5GwgWMWemsLB2ziYtFbW0ky5UppdTUOm4QiEgQuBlYSHqY6LuMMfZ0FZZtAw8+RLQgTH9eAL+JUxMN0V8R1L0BpdScc6Kuof8CmoHtwJXAv01LRTOAPTzMgccew/F4aCuvppH9RGLzCNbr3oBSau450VlDyyecNfQDYMP0lJR9Q7/8JcP+EC0VtfQVlXGt+THu6BKqrqrNdmlKKTXlJnvWUM50CQHENr5If/VCOgtLCaZinMczdMZKqSwNZbs0pZSacifaIzh9wtlBAuSNTwtgjDFztp8k1dVFX30zA6ECquKdSBj2SFiPDyil5qQT7RFsNcZExh8FxhjvhOdzNgSMbZPYvZvBcICegiKWpLoB2BMpyXJlSimVGScKAjNtVcwgydZWjOOwrzyCY3k517MRb7SaM1cuznZpSimVESfqGqoQkU8fb6Ex5usZqCfrRp97nrFgKdFgelC5isABRgcauO5tDVmuTCmlMuNEQWABYdLHBHKG3dNDX8kixgLpYabz/R24nEZ+UG/vrJSam060des0xnxh2iqZIZzhIXrK5xPzBQikxvB6k6R887JdllJKZcyJjhHk1J7AYc7gEP2FEUby8ilNpk+acorrslyVUkplzomC4JJpq2IGGT5wiLgvynAwRJ0dB6CkdlGWq1JKqcw5bhAYY/qns5CZ4tCIH9sTJxoMUeNEAVhWp0GglJq79AjoUQbzGoiFDY7HoohBbDuPorDef0ApNXdpEExgkkmi4Xq2NaV/LTW+ncSTeiGZUmpuO9Exgpxj9/fzankBGxes5PT+P7Ak/FsODa3NdllKKZVRGgQTDG98iedWhPEYl4/3PogAI94/yXZZSimVURoEEwy+uJ2BAqEoFqUyPAyJCOFKvaJYKTW3ZTQIRORyEdklIi0i8tkTrHe2iDgicnUm63kjsa4+RvN8hBIxEsXtjAws4gy9Ub1Sao7LWBCIiAXcBlwBLAeuE5Hlx1nvX4FHMlXLZPVHo0SDISJuP3ZwiP7elZzdqAeLlVJzWyb3CM4BWowx+4wxSeAe4KpjrPcJ4F6gO4O1TMq+gJ+xQB711gEAugdO03sQKKXmvEwGQQ3QNmG6fXzeESJSA7wbuP1EbyQiN4nIiyLyYk9Pz5QXetgP1l6C17E537OBwEgdrX7tFlJKzX2ZDIJjfZU++h4H3wQ+Y4xxTvRGxpg7jDHNxpjm8vLyqarvNVpHRmmpreOM1t3MD7bgi1WSLPRn5LOUUmomyeQFZe3AxNHaaoGOo9ZpBu4Z734pA64UEdsY8+sM1nVMP97TCsDK7lcwjXFC+5dRXJI33WUopdS0y2QQbAQWiUgTcBC4Frh+4grGmKbDz0Xkh8CD2QgBYwy/GoxRNdRPrXswPXOklqrF+dNdilJKTbuMdQ0ZY2zgVtJnA+0Efm6M2SEiN4vIzZn63JPRFk/SLhYLejqIlA6A6yEarWFpZUG2S1NKqYzL6FhDxph1wLqj5h3zwLAx5kOZrOVEhu30IYr8RJxwVS+BoVr63TwuXVaRrZKUUmra6JXFQE/SBsDnpAiF+whEG/FXhAj4rCxXppRSmaejjwKPbtsJBKhLteD1JwkNLSb/NN0bUErlhpwPAscYfmZ7WNDbSrnnEADB4QbqTq/McmVKKTU9cr5rqH0sSczro763i2BwFADPWCm+iF5DoJTKDTkfBN2pFAAB1yEYHMOTCtFaXITo8QGlVI7I+a6hwVT6jKGAa5MfHsEXq2DFebVZrkoppaZPzu8R9EfT3UEhN0p+aS/5fSsJFgezXJVSSk2fnA+C3p5eACoLWhGPoWDoDAILi7JblFJKTaOcD4L+WByA6oK9WIkIhaWn4fHr8QGlVO7I+WMEPWMJfJZQnN9N3uBi/JU69LRSKrfk/B7BftuhMDZCMDSKL1aBpSOOKqVyTM4HwavipSzVj8fjEhxuwtIDxUqpHJPTQZBwXXrz8qnypG+TkDe0AG9xIMtVKaXU9MrpINgXS2BEWBh6hVRfDb54KVahBoFSKrfkdBDsGk2fMVTv30fewHw8+T49Y0gplXNyOgj+MJy+mGweHZTHFmJpt5BSKgfldBC8MjBExBnGO+ZS0Hcu3lI9Y0gplXtyOgj2RWNUmk7i/cVIKoCvMpTtkpRSatrldBB0OTCPTqxUukvIN09vVq+Uyj05GwRR2yHq9VElB/Hb6S4hb7l2DSmlck/OBkFrPAnAPE8nweFqALx6MZlSKgflbBD0jAdBAcMUjVQifg/izdlfh1Iqh+Xslu+Frh4AShJ9FLnVePJ8Wa5IKaWyI2eDYH//IAAFQym8qZUEFhVltR6llMqWnB2Gujc+RsjrITTYBGIovLIp2yUppVRW5OweQW88RhEDFMUX4S93sELaNaSUyk05GwRDHiihl8Kx+fgWVGe7HKWUypqcDALHNYz48yilD3+sCn+t3pVMKZW7cjIIXtjbS9QbpsgZxEqFCSwozHZJSimVNTkZBE+tb8eIh8J4nKQnofcgUErltIwGgYhcLiK7RKRFRD57jOXvE5Ft44/nRGR1Jus57GD3NgAqhoqIFfYjItPxsUopNSNlLAhExAJuA64AlgPXicjyo1bbD1xojFkFfBG4I1P1TGQV7QWgqruBsrMrp+MjlVJqxsrkHsE5QIsxZp8xJgncA1w1cQVjzHPGmIHxyfVAbQbrAaDvYAd2YfrOZPOGiimePy07IUopNWNlMghqgLYJ0+3j847no8Bvj7VARG4SkRdF5MWenp5TKmrL01tJRgKIcSlJClaRDjSnlMptmQyCY3W8m2OuKLKWdBB85ljLjTF3GGOajTHN5eXlp1TUwVf343gtvMbBtoewInqgWCmV2zIZBO1A3YTpWqDj6JVEZBVwJ3CVMaYvg/UAEBvcRYIAlnHoC3QhHj1QrJTKbZkMgo3AIhFpEhE/cC1w/8QVRKQeuA94vzFmdwZrAcCxU9hD+9jNMubF+8gr1esHlFIqY4POGWNsEbkVeASwgLuMMTtE5Obx5bcDnwNKge+Mn8JpG2OaM1XTof17SfgM7dSxdnQbdfULMvVRSik1a2R09FFjzDpg3VHzbp/w/EbgxkzWMNFQ9yH21izFFYvTBruZd9Ha6fpopZSasXLqyuKxoUFG88IA1I6MEpinYwwppVROBUEyPsZoXhjL2BRFx/Dk6c3qlVIqp4LAsW1ieQVEGMIXiyN+f7ZLUkqprMutIEjZjAUjFDCMLz6W7XKUUmpGyKkgiI8mGQ2EiTCE3znmtW1KKZVzcioIUokUo758Chki5LOyXY5SSs0IuRUESZuoL598d5SikB4oVkopyLEgGEk5JDwB8u0xInX12S5HKaVmhJwKgoHxcfAKkgkCCxZluRqllJoZcioIhvABUBhL4m9akuVqlFJqZsipIBj2p4ecLh0axVerXUNKKQU5FgSjvvTQSpGhUb2qWCmlxuVUEPRG8vCaFAXDw9kuRSmlZoycCoLB/CAVdOEZi2e7FKWUmjFyKgjiPiGPMWxLh5dQSqnDcioIkl4vQeI4Ab1PsVJKHZZTQZCyLPwk8ZXXvfHKSimVI3IqCByPB8t1CS5fmu1SlFJqxsipILA9FpZjiFTWZrsUpZSaMXIrCMTCa1wKQhXZLkUppWaM3AoCvHhdh3BRY7ZLUUqpGSNngsAkk6TEi+Ua8kNl2S5HKaVmjJwJArunJ71H4BjC/nC2y1FKqRkjZ4JgrLMLR7xYDgQsvY5AKaUOy5kgiI30A2A5WS5EKaVmmJwJgmhiFADLcbNciVJKzSw5EwQj8XQQeB2T5UqUUmpmyZkgGBhLDzTndXWPQCmlJsqZIOgbswGwbDvLlSil1MySM0EwZKcA8DkaBEopNVHOBMGomw4Ar6unDSml1EQZDQIRuVxEdolIi4h89hjLRUS+Nb58m4icmalahoIWAAE9VqyUUq+RsSAQEQu4DbgCWA5cJyLLj1rtCmDR+OMm4LuZqidO+iBxHpoESik1USb3CM4BWowx+4wxSeAe4Kqj1rkK+JFJWw8UiUhVJopJetJnDRV4c6Y3TCmlJsWbwfeuAdomTLcDayaxTg3QOXElEbmJ9B4D9fX1J1XMuUGLwODdnH/6pSf1eqWUmqsyGQRyjHlH98tMZh2MMXcAdwA0NzefVN/O1X/+t1x9Mi9USqk5LpP9JO3AxJsD1wIdJ7GOUkqpDMpkEGwEFolIk4j4gWuB+49a537gA+NnD50LDBljOo9+I6WUUpmTsa4hY4wtIrcCjwAWcJcxZoeI3Dy+/HZgHXAl0ALEgA9nqh6llFLHlsljBBhj1pHe2E+cd/uE5wa4JZM1KKWUOjE9l1IppXKcBoFSSuU4DQKllMpxGgRKKZXjJH28dvYQkR7gwEm+vAzoncJyZgNtc27QNueGU2lzgzGm/FgLZl0QnAoRedEY05ztOqaTtjk3aJtzQ6barF1DSimV4zQIlFIqx+VaENyR7QKyQNucG7TNuSEjbc6pYwRKKaVeL9f2CJRSSh1Fg0AppXLcnAwCEblcRHaJSIuIfPYYy0VEvjW+fJuInJmNOqfSJNr8vvG2bhOR50RkdTbqnEpv1OYJ650tIo6IzPp7E02mzSJykYhsEZEdIvLkdNc41Sbxb7tQRB4Qka3jbZ7VoxiLyF0i0i0iLx9n+dRvv4wxc+pBesjrvcB8wA9sBZYftc6VwG9J3yHtXOCFbNc9DW0+Hygef35FLrR5wnqPkx4F9+ps1z0Nf+ci4BWgfny6Itt1T0Ob/x741/Hn5UA/4M927afQ5j8BzgRePs7yKd9+zcU9gnOAFmPMPmNMErgHuOqoda4CfmTS1gNFIlI13YVOoTdsszHmOWPMwPjketJ3g5vNJvN3BvgEcC/QPZ3FZchk2nw9cJ8xphXAGDPb2z2ZNhugQEQECJMOAnt6y5w6xpinSLfheKZ8+zUXg6AGaJsw3T4+782uM5u82fZ8lPQ3itnsDdssIjXAu4HbmRsm83deDBSLyBMisklEPjBt1WXGZNr8bWAZ6dvcbgc+aYxxp6e8rJjy7VdGb0yTJXKMeUefIzuZdWaTSbdHRNaSDoK3ZrSizJtMm78JfMYY46S/LM56k2mzFzgLuATIA54XkfXGmN2ZLi5DJtPmtwNbgIuBBcDvRORpY8xwhmvLlinffs3FIGgH6iZM15L+pvBm15lNJtUeEVkF3AlcYYzpm6baMmUybW4G7hkPgTLgShGxjTG/npYKp95k/233GmNGgVEReQpYDczWIJhMmz8MfNmkO9BbRGQ/sBTYMD0lTrsp337Nxa6hjcAiEWkSET9wLXD/UevcD3xg/Oj7ucCQMaZzugudQm/YZhGpB+4D3j+Lvx1O9IZtNsY0GWMajTGNwC+Bv5rFIQCT+7f9G+ACEfGKSAhYA+yc5jqn0mTa3Ep6DwgRqQSWAPumtcrpNeXbrzm3R2CMsUXkVuAR0mcc3GWM2SEiN48vv530GSRXAi1AjPQ3illrkm3+HFAKfGf8G7JtZvHIjZNs85wymTYbY3aKyMPANsAF7jTGHPM0xNlgkn/nLwI/FJHtpLtNPmOMmbXDU4vIT4GLgDIRaQc+D/ggc9svHWJCKaVy3FzsGlJKKfUmaBAopVSO0yBQSqkcp0GglFI5ToNAKaVynAaBUpM0PoLplgmPxvGRPodEZLOI7BSRz4+vO3H+H0Tka9muX6njmXPXESiVQWPGmNMnzhCRRuBpY8w7RCQf2CIiD44vPjw/D9gsIr8yxjw7vSUr9cZ0j0CpKTI+rMMm0uPdTJw/RnosnNk8sKGawzQIlJq8vAndQr86eqGIlJIeH37HUfOLgUXAU9NTplJvjnYNKTV5r+saGneBiGwmPaTDl8eHQLhofP420mPffNkY0zVtlSr1JmgQKHXqnjbGvON480VkMfDM+DGCLdNcm1JvSLuGlMqw8dFe/wX4TLZrUepYNAiUmh63A38iIk3ZLkSpo+noo0opleN0j0AppXKcBoFSSuU4DQKllMpxGgRKKZXjNAiUUirHaRAopVSO0yBQSqkc9/8DlZIxhi1adgYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df, features = load_df(debug=True)\n",
    "df = preprocess_data(df, features)\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=RND_SEED)\n",
    "\n",
    "for i, (train_ids, test_ids) in enumerate(skf.split(df.drop(columns='y'), df.y)):\n",
    "    train_df, test_df = df.iloc[train_ids], df.iloc[test_ids]\n",
    "    model = XGBClassifier(use_label_encoder=False, eval_metric='auc', max_depth=23, n_estimators=30,\n",
    "                          eta=0.05, subsample=0.5, colsample_bytree=0.5)\n",
    "    model.fit(train_df.drop(columns='y'), train_df.y)\n",
    "    \n",
    "    y_proba = model.predict(test_df.drop(columns='y'), output_margin=True)\n",
    "    fpr, tpr, _ = roc_curve(test_df.y, y_proba)\n",
    "    res = {'FPR':fpr, 'TPR':tpr}\n",
    "    sns.lineplot(data=res, x=\"FPR\", y=\"TPR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5324116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:24<00:00,  1.44s/trial, best loss: -0.9256452488687783]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"algo_hyperopt = HyperOptSearch(config, metric='AUC', mode='max', n_initial_points=10)\\nscheduler_asha = ASHAScheduler(\\n    time_attr='training_iteration',\\n    metric='AUC', mode='max',\\n    max_t=60,\\n    grace_period=7,\\n    reduction_factor=4,\\n)\\n\\nanalysis = tune.run(\\n    run,\\n    metric='AUC', mode='max',\\n    #scheduler=scheduler_asha, search_alg=algo_hyperopt,\\n    config=config,\\n    local_dir='./results',\\n    trial_name_creator=lambda trial: trial.trainable_name + '_' + trial.trial_id,\\n    resources_per_trial={'gpu': 1},\\n    num_samples = 2\\n    )\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "config = {\n",
    "        \"eval_metric\": [\"auc\"],\n",
    "        \"max_depth\": hp.quniform('max_depth', 1, 30, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        \"n_estimators\": hp.quniform('n_estimators', 1, 30, 1),\n",
    "        \"subsample\": hp.uniform('subsample', 0.5, 1.0),\n",
    "        \"colsample_bytree\": hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        \"eta\": hp.loguniform('eta', 1e-4, 1e-1)\n",
    "    }\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = run,\n",
    "                        space = config,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials,\n",
    "                        verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''algo_hyperopt = HyperOptSearch(config, metric='AUC', mode='max', n_initial_points=10)\n",
    "scheduler_asha = ASHAScheduler(\n",
    "    time_attr='training_iteration',\n",
    "    metric='AUC', mode='max',\n",
    "    max_t=60,\n",
    "    grace_period=7,\n",
    "    reduction_factor=4,\n",
    ")\n",
    "\n",
    "analysis = tune.run(\n",
    "    run,\n",
    "    metric='AUC', mode='max',\n",
    "    #scheduler=scheduler_asha, search_alg=algo_hyperopt,\n",
    "    config=config,\n",
    "    local_dir='./results',\n",
    "    trial_name_creator=lambda trial: trial.trainable_name + '_' + trial.trial_id,\n",
    "    resources_per_trial={'gpu': 1},\n",
    "    num_samples = 2\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c439d3",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40d41b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HYPER-PARAMETERS\n",
    "batch_size = 100\n",
    "act_function = 'tanh'\n",
    "hidden_units = [512, 256, 128, 64, 32]\n",
    "optimizer = 'nadam'\n",
    "\n",
    "#loss_function = BinaryFocalLoss(gamma=4)\n",
    "loss_function = \"binary_crossentropy\"\n",
    "\n",
    "metrics = ['accuracy',\n",
    "           tf.keras.metrics.Precision(),\n",
    "           tf.keras.metrics.Recall()]\n",
    "\n",
    "RND_SEED = 42\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc8b4a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 4153 (9.6%) samples\n",
      "Train samples: 36944, Test samples: 2000\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df, features = load_df(debug=debug)\n",
    "#df = midsampling(df, debug)\n",
    "train_ds, test_ds = get_train_test_dataset(df, test_size=2000, debug=debug)\n",
    "\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "test_ds = test_ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "294b96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "#tf.keras.backend.clear_session()\n",
    "model = get_model(df, features, hidden_units, act_function)\n",
    "\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=loss_function,\n",
    "              metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3af3c447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "370/370 [==============================] - 5s 9ms/step - loss: 0.9631 - accuracy: 0.9359 - precision_2: 0.0278 - recall_2: 8.6957e-04 - val_loss: 1.0103 - val_accuracy: 0.9345 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 2/100\n",
      "370/370 [==============================] - 3s 7ms/step - loss: 0.9603 - accuracy: 0.9377 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.9345 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 3/100\n",
      "370/370 [==============================] - 2s 6ms/step - loss: 0.9603 - accuracy: 0.9377 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.9345 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 4/100\n",
      "370/370 [==============================] - 2s 5ms/step - loss: 0.9603 - accuracy: 0.9377 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.9345 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 5/100\n",
      "370/370 [==============================] - 2s 5ms/step - loss: 0.9603 - accuracy: 0.9377 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.9345 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 6/100\n",
      "370/370 [==============================] - 2s 5ms/step - loss: 0.9603 - accuracy: 0.9377 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.9345 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 7/100\n",
      "370/370 [==============================] - 2s 5ms/step - loss: 0.9603 - accuracy: 0.9377 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.9345 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "Epoch 8/100\n",
      "370/370 [==============================] - 2s 5ms/step - loss: 0.9603 - accuracy: 0.9377 - precision_2: 0.0000e+00 - recall_2: 0.0000e+00 - val_loss: 1.0103 - val_accuracy: 0.9345 - val_precision_2: 0.0000e+00 - val_recall_2: 0.0000e+00\n",
      "train done!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Train the model\n",
    "log_dir = \"logs/\" + datetime.now().strftime(\"%m%d-%H%M%S\")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=7, restore_best_weights=True),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "]\n",
    "history = model.fit(train_ds, epochs=100, validation_data=test_ds, callbacks=callbacks)\n",
    "print(\"train done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ae992d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('DSS2.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "36f7d69ef84ec5cb78743e4eea0bd660bae13cdc2d9a04d858d23d1287c2b0cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
